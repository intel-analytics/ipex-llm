# Self-Speculative Decoding for Large Language Model Inference using IPEX-LLM on Intel CPUs

This folder contains examples of running Self-Speculative Decoding on IPEX-LLM:

- [Self-Speculation](Self-Speculation): examples of running run BF16 inference for any Huggingface Transformer model with self-speculative decoding
- [Eagle](Eagle): examples of running EAGLE (Extrapolation Algorithm for Greater Language-model Efficiency) speculative decoding
