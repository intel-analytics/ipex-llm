{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\n",
    "    .rst-content blockquote {\n",
    "\n",
    "        margin-left: 0px;\n",
    "\n",
    "    }\n",
    "\n",
    "   \n",
    "\n",
    "    blockquote > div {\n",
    "\n",
    "        margin: 1.5625em auto;\n",
    "\n",
    "        padding: 20px 15px 1px;\n",
    "\n",
    "        border-left: 0.2rem solid rgb(59, 136, 219);  \n",
    "\n",
    "        border-radius: 0.2rem;\n",
    "\n",
    "        box-shadow: 0 0.2rem 0.5rem rgb(0 0 0 / 5%), 0 0 0.0625rem rgb(0 0 0 / 10%);\n",
    "\n",
    "    }\n",
    "\n",
    "</style>\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Examples for InferenceOptimizer\n",
    "\n",
    "Today, vision Transformer is becoming more and more popular. On one hand, people are constantly searching for larger pre-training corpus and pre-training model, on the other hand, how to deploy the vision transformer in the industrial scene is also a very sought-after issue.\n",
    "\n",
    "Here we take several popular vision Transformer architectures as examples to demonstrate how to use InferenceOptimizer in BigDL-Nano to accelerate model's inference speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  step 0 : Prepare the environment\n",
    "We recommend you to use [Miniconda](https://docs.conda.io/en/latest/miniconda.html) to prepare the environment.\n",
    "\n",
    "**Note**: during your installation, there may be some warnings or errors about version, just ignore them.\n",
    "```bash\n",
    "conda create -n nano python=3.7 setuptools=58.0.4 # \"nano\" is conda environment name, you can use any name you like.\n",
    "conda activate nano\n",
    "pip install --pre --upgrade bigdl-nano[pytorch,inference]  # install the nightly-bulit version\n",
    "# install timm package to use pre-trained model\n",
    "pip install timm\n",
    "```\n",
    "\n",
    "Initialize environment variables with script `bigdl-nano-init` installed with bigdl-nano.\n",
    "\n",
    "```bash\n",
    "source bigdl-nano-init\n",
    "``` \n",
    "\n",
    "You may find environment variables set like follows:\n",
    "\n",
    "```\n",
    "conda dir found: /opt/anaconda3/envs/nano/bin/..\n",
    "OpenMP library found...\n",
    "Setting OMP_NUM_THREADS...\n",
    "Setting OMP_NUM_THREADS specified for pytorch...\n",
    "Setting KMP_AFFINITY...\n",
    "Setting KMP_BLOCKTIME...\n",
    "Setting MALLOC_CONF...\n",
    "Setting LD_PRELOAD...\n",
    "nano_vars.sh already exists\n",
    "+++++ Env Variables +++++\n",
    "LD_PRELOAD=/opt/anaconda3/envs/nano/bin/../lib/libiomp5.so /opt/anaconda3/envs/nano/lib/python3.7/site-packages/bigdl/nano//libs/libtcmalloc.so\n",
    "MALLOC_CONF=\n",
    "OMP_NUM_THREADS=112\n",
    "KMP_AFFINITY=granularity=fine\n",
    "KMP_BLOCKTIME=1\n",
    "TF_ENABLE_ONEDNN_OPTS=1\n",
    "ENABLE_TF_OPTS=1\n",
    "NANO_TF_INTER_OP=1\n",
    "+++++++++++++++++++++++++\n",
    "Complete.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1 : Prepare Dataset\n",
    "\n",
    "As InferenceOptimizer needs validation data to calculate accuracy metric, we need to download [ImageNet validation dataset](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar) and [development kit](https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz), and place them under directory `./img_data`.\n",
    "\n",
    "Here we provide a helper function `create_imagenet_val_dataset` to help users create a subset of ImageNet validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def create_imagenet_val_dataset(limit_num_samples=None):\n",
    "    dataset = ImageNet(root=\"img_data\", split=\"val\")\n",
    "    if limit_num_samples is not None:\n",
    "        indices = np.random.permutation(len(dataset))[:limit_num_samples]\n",
    "        dataset = Subset(dataset, indices)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2 : Import related package\n",
    "\n",
    "[PyTorch Image Models (timm)](https://github.com/rwightman/pytorch-image-models) provides a collection of image models. Here we use some vision Transformer models with pre-trained weights provided by timm to demonstrate acceleration of InferenceOptimizer in BigDL-Nano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigdl.nano.pytorch import InferenceOptimizer\n",
    "import timm\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3 : Define dataloader, model then optimize and get_best_model\n",
    "> ðŸ“ **Note**\n",
    ">\n",
    "> Actually we highly recommand users pass real training dataloader to `training_data` for calibration of quantization. But as ImageNet training set is too large to download, we just use validation dataset as faked training dataset in blow cases.\n",
    "> \n",
    "> If you want to get real performance on ImageNet validation set, you can just set `limit_num_samples=None`. Here we choose a subset to make inference pipeline faster and we just want to get a rough metric to evaluate the effect of quantization.\n",
    "> \n",
    "> Below results is obtained on a Cooper Lake processor with 112 physical cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MobileViT\n",
    "\n",
    "[MobileViT](https://arxiv.org/abs/2110.02178) is a light-weight, general-purpose, and mobile-friendly vision Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                                       input_size=256,\n",
    "                                       # in case we want to evaluate single sample latency, so set batch_size to 1\n",
    "                                       batch_size=1,\n",
    "                                       use_prefetcher=False,\n",
    "                                       no_aug=True,\n",
    "                                       crop_pct=0.9,\n",
    "                                       interpolation=\"bicubic\",\n",
    "                                       mean=(0.0, 0.0, 0.0),\n",
    "                                       std=(1.0, 1.0, 1.0),\n",
    "                                       persistent_workers=False)\n",
    "\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=256,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.0, 0.0, 0.0),\n",
    "                               std=(1.0, 1.0, 1.0),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸ“ **Note**\n",
    ">\n",
    "> Each model has its own data preprocessing and these parameters for data loader is found in timm.\n",
    "> \n",
    "> `val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform` is used to apply transform on subset dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate latency using 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"mobilevit_xxs\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling `optimizer.summary()`, you can see the complete optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |    24.833    |        0.656         |\n",
      "|           fp32_ipex            |      successful      |    26.223    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |      successful      |   174.994    |        0.666         |\n",
      "|              int8              |      successful      |    25.756    |        0.003         |\n",
      "|            jit_fp32            |      successful      |    20.159    |    not recomputed    |\n",
      "|         jit_fp32_ipex          |      successful      |    19.678    |    not recomputed    |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |    15.097    |    not recomputed    |\n",
      "|         openvino_fp32          |      successful      |    10.519    |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |    83.762    |        0.641         |\n",
      "|        onnxruntime_fp32        |      successful      |    12.811    |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    11.756    |        0.003         |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 180.1s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `optimizer.optimize`, you need to call `get_best_model()` to obtain an accelarated model which meet certain restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When accuracy drop less than 5%, the model with minimal latency is:  openvino \n"
     ]
    }
   ],
   "source": [
    "acc_model, option = optimizer.get_best_model(accuracy_criterion=0.05)\n",
    "print(\"When accuracy drop less than 5%, the model with minimal latency is: \", option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then You can use the accelarated model as normal nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with InferenceOptimizer.get_context(acc_model):\n",
    "    input_sample = next(iter(val_dataloader))[0]\n",
    "    target = acc_model(input_sample).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate latency using 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"mobilevit_xxs\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |    27.307    |        0.656         |\n",
      "|           fp32_ipex            |      successful      |    28.656    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |    early stopped     |   388.867    |         None         |\n",
      "|              int8              |      successful      |    25.721    |        0.003         |\n",
      "|            jit_fp32            |      successful      |    23.366    |    not recomputed    |\n",
      "|         jit_fp32_ipex          |      successful      |    22.259    |    not recomputed    |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |    18.506    |    not recomputed    |\n",
      "|         openvino_fp32          |      successful      |    3.832     |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |     92.5     |        0.641         |\n",
      "|        onnxruntime_fp32        |      successful      |    5.288     |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    5.721     |        0.003         |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 172.0s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PoolFormer\n",
    "\n",
    "[PoolFormer](https://arxiv.org/abs/2111.11418) verifys that the general architecture of the Transformers, instead of the specific token mixer module, is more essential to the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=320)\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=32,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate latency using 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"poolformer_s12\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |    49.345    |        0.756         |\n",
      "|           fp32_ipex            |      successful      |    51.116    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |    early stopped     |   1017.334   |         None         |\n",
      "|              int8              |   fail to convert    |     None     |         None         |\n",
      "|            jit_fp32            |    early stopped     |   447.881    |         None         |\n",
      "|         jit_fp32_ipex          |    early stopped     |   454.322    |         None         |\n",
      "|  jit_fp32_ipex_channels_last   |    early stopped     |   913.834    |         None         |\n",
      "|         openvino_fp32          |      successful      |    23.586    |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |    39.072    |        0.753         |\n",
      "|        onnxruntime_fp32        |      successful      |    33.916    |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    30.98     |        0.747         |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 144.6s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate latency using 4 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"poolformer_s12\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |    23.68     |        0.756         |\n",
      "|           fp32_ipex            |      successful      |    22.179    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |    early stopped     |   576.108    |         None         |\n",
      "|              int8              |   fail to convert    |     None     |         None         |\n",
      "|            jit_fp32            |    early stopped     |   434.256    |         None         |\n",
      "|         jit_fp32_ipex          |    early stopped     |   445.771    |         None         |\n",
      "|  jit_fp32_ipex_channels_last   |    early stopped     |   814.551    |         None         |\n",
      "|         openvino_fp32          |      successful      |    8.511     |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |    41.941    |        0.759         |\n",
      "|        onnxruntime_fp32        |      successful      |    20.252    |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    17.188    |        0.747         |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 140.4s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Swin Transformer\n",
    "\n",
    "[Swin Transformer](https://arxiv.org/abs/2103.14030) proposes hierarchical vision Transformer using shifted windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> âš ï¸ **Warning**\n",
    ">\n",
    "> Swin don't support dynamic batch, so the batch_size of faked_train_dataloader must be the same with val_dataloader.\n",
    ">\n",
    "> Otherwise the accuracy will be very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import Interpolation\n",
    "from timm.data.loader import create_loader\n",
    "\n",
    "fake_train_dataset = create_imagenet_val_dataset()\n",
    "faked_train_dataloader = create_loader(fake_train_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataset = create_imagenet_val_dataset(limit_num_samples=20)\n",
    "val_dataloader = create_loader(val_dataset,\n",
    "                               input_size=224,\n",
    "                               batch_size=1,\n",
    "                               use_prefetcher=False,\n",
    "                               no_aug=True,\n",
    "                               crop_pct=0.9,\n",
    "                               interpolation=\"bicubic\",\n",
    "                               mean=(0.485, 0.456, 0.406),\n",
    "                               std=(0.229, 0.224, 0.225),\n",
    "                               persistent_workers=False)\n",
    "val_dataloader.dataset.dataset.transform = val_dataloader.dataset.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate latency using 1 thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |   317.182    |         0.8          |\n",
      "|           fp32_ipex            |      successful      |   317.513    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |    early stopped     |   877.588    |         None         |\n",
      "|              int8              |      successful      |   181.608    |         0.85         |\n",
      "|            jit_fp32            |      successful      |    282.91    |    not recomputed    |\n",
      "|         jit_fp32_ipex          |      successful      |   291.576    |    not recomputed    |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |    286.76    |    not recomputed    |\n",
      "|         openvino_fp32          |      successful      |    168.88    |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |   241.399    |         0.0          |\n",
      "|        onnxruntime_fp32        |      successful      |   275.598    |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |   140.532    |         0.6          |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 750.8s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate latency using 8 threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True)\n",
    "\n",
    "optimizer = InferenceOptimizer()\n",
    "optimizer.optimize(model,\n",
    "                   training_data=faked_train_dataloader,\n",
    "                   validation_data=val_dataloader,\n",
    "                   metric=Accuracy(),\n",
    "                   direction=\"max\",\n",
    "                   thread_num=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|             method             |        status        | latency(ms)  |       accuracy       |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "|            original            |      successful      |    97.609    |         0.8          |\n",
      "|           fp32_ipex            |      successful      |    103.43    |    not recomputed    |\n",
      "|              bf16              |   fail to forward    |     None     |         None         |\n",
      "|           bf16_ipex            |    early stopped     |   1245.375   |         None         |\n",
      "|              int8              |      successful      |    85.048    |         0.85         |\n",
      "|            jit_fp32            |      successful      |    78.076    |    not recomputed    |\n",
      "|         jit_fp32_ipex          |      successful      |    76.323    |    not recomputed    |\n",
      "|  jit_fp32_ipex_channels_last   |      successful      |    75.076    |    not recomputed    |\n",
      "|         openvino_fp32          |      successful      |    37.326    |    not recomputed    |\n",
      "|         openvino_int8          |      successful      |    194.96    |         0.0          |\n",
      "|        onnxruntime_fp32        |      successful      |    81.021    |    not recomputed    |\n",
      "|    onnxruntime_int8_qlinear    |      successful      |    62.608    |         0.6          |\n",
      "|    onnxruntime_int8_integer    |   fail to convert    |     None     |         None         |\n",
      " -------------------------------- ---------------------- -------------- ----------------------\n",
      "Optimization cost 733.8s in total.\n"
     ]
    }
   ],
   "source": [
    "optimizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step4 : save and load model (optional)\n",
    "After you get an accelerated model, you can save it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "InferenceOptimizer.save(acc_model, path=\"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load it by `InferenceOptimizer.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceOptimizer.load(\"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('ruonan_nano')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d347a5dca25745bedb029e46e41f7d6c8c9b5181ecb97033e2e81a7538459254"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
