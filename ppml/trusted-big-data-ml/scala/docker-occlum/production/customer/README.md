# Trusted Big Data ML with Occlum for customer
This director is for reducing occlum runable instance image size.
We assume the ${FINAL_NAME} is already build in ../production.

You can see building command in [manually_build.yaml](https://github.com/intel-analytics/BigDL/blob/main/.github/workflows/manually_build.yml#L526) : bigdl-ppml-trusted-big-data-ml-scala-occlum-production-customer.
It will build image by coping occlum runable instance (/opt/occlum_spark) and install necessary dependencies.

the final image is called `intelanalytics/bigdl-ppml-trusted-big-data-ml-scala-occlum-production-customer:${TAG}`.

## Get customer image.

### Pull customer image from dockerhub
```bash
docker pull intelanalytics/bigdl-ppml-trusted-big-data-ml-scala-occlum-production-customer:2.5.0-SNAPSHOT-build
```
### Build customer image from production-build image
```bash
cd /path/BigDL/ppml/trusted-big-data-ml/scala/docker-occlum/
#update config
bash build-customer-image.sh
```

## Using BigDL PPML Occlum EHSM Attestation
Bigdl ppml use EHSM as reference KMS&AS, you can deploy EHSM following the [guide](https://github.com/intel-analytics/BigDL/tree/main/ppml/services/ehsm/kubernetes#deploy-bigdl-ehsm-kms-on-kubernetes-with-helm-charts)
We assume you have already set up environment and enroll yourself on EHSM.

In [start-spark-local.sh](https://github.com/intel-analytics/BigDL/blob/main/ppml/trusted-big-data-ml/scala/docker-occlum/production/start-spark-local.sh). Set `ATTESTATION` = true and modify `PCCL_URL`, `ATTESTATION_URL` to the env value you have set,
and modify `APP_ID`, `API_KEY` to the value you have get  when enroll, and then you can change `CHALLENGE` and
`REPORT_DATA` for attestation.

``` bash
#start-spark-local.sh
-e ATTESTATION=false \   set to true to start attestation.
-e PCCS_URL=https://PCCS_IP:PCCS_PORT \  PCCS URL, obtained from KMS services or a self-deployed one. Should match the format https://<ip_address>:<port>.
-e ATTESTATION_URL=ESHM_IP:EHSM_PORT \  URL of attestation service. Should match the format <ip_address>:<port>.
-e APP_ID=your_app_id \ The appId generated by your attestation service.
-e API_KEY=your_api_key \ The apiKey generated by your attestation service.
-e CHALLENGE=cHBtbAo= \ Challenge to get quote of attestation service which will be verified by local SGX SDK. Should be a BASE64 string. It can be a casual BASE64 string, for example, it can be generated by the command echo ppml|base64.
-e REPORT_DATA=ppml \ A random String to generator a quote which will be send to attestation service and use for attest. Default is ppml.
```
### Register and get policy_Id
1. Verify that the attestation server is trusted.
```bash
bash start-spark-local.sh verify
```
2. Register application on attestation server
```bash
bash start-spark-local.sh register
```
3. Get the policy_Id and save for running this occlum application.
```bash
policy_Id ${policy_Id}
```

### Run application in docker and k8s

#### Docker
Set policy_Id to ENV and run application as usual.
```
export policy_Id=${policy_Id}
```
or
```bash
#start-spark-local.sh
-e ${policy_Id}
```

#### K8s
Add policy_Id to driver and executor ENV and run application as usual..
```yaml
#driver.yaml
env:
  - name: policy_Id
    value: "${policy_Id}"
```

```yaml
#executor.yaml
env:
  - name: policy_Id
    value: "${policy_Id}"
```